{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "from numpy.linalg import inv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### Helper functions ####\n",
    "\n",
    "def generate_point():\n",
    "    '''Generate a random point in [-1, 1] x [-1, 1]'''\n",
    "    return [random.uniform(-1, 1), random.uniform(-1, 1)]\n",
    "\n",
    "def define_f():\n",
    "    '''Return a slope and y-intercept based on two random points in\n",
    "       [-1, 1] x [-1, 1]. This defines the function f(x) = slope * x + y_int. \n",
    "       This can fail if f is vertical. However, this is extremely unlikely given \n",
    "       that our two points are chosen randomly. If it does fail, we'll get an error.'''\n",
    "    p1 = generate_point()\n",
    "    p2 = generate_point()\n",
    "    slope = (p2[1] - p1[1]) / (p2[0] - p1[0])\n",
    "    y_int = (-1 * slope * p1[0]) + p1[1] # From point-slope form\n",
    "    return slope, y_int\n",
    "\n",
    "def evaluate_point(pt, slope, y_int):\n",
    "    ''' Return 1 if the point is above f, -1 otherwise'''\n",
    "    if pt[1] >= slope * pt[0] + y_int: # pt[0] is x coord, pt[1] is y coord\n",
    "        return 1\n",
    "    return -1\n",
    "\n",
    "def build_training_set(N, slope, y_int):\n",
    "    '''Build a set of N training points of the form ([1.0, x1, x2], y). The 1.0 is the\n",
    "       artificial coordinate used to simplify the math. x1 and x2 come from\n",
    "       [-1, 1] x [-1, 1], and y is -1 or +1, depending on whether the point (x1, x2) is\n",
    "       above or below f. f is defined by f(x) = slope * x + y_int'''\n",
    "    training_set = []\n",
    "    for i in range(N):\n",
    "        xn = generate_point() \n",
    "        yn = evaluate_point(xn, slope, y_int)\n",
    "        training_set.append(([1.] + xn, yn)) # Note the artificial coordinate\n",
    "    return training_set\n",
    "    \n",
    "def eval_PLA(pt, weights):\n",
    "    '''Classify the given point as +1 or -1 based on the the given weights vector'''\n",
    "    return np.sign(np.dot(weights, np.array(pt)))\n",
    "\n",
    "def train_PLA(training_set, W=None):\n",
    "    '''Train the PLA on training_set until it converges to f. \n",
    "       Return the number of iterations needed, along with the \n",
    "       final weight vector.'''\n",
    "    if W is None:\n",
    "        W = np.zeros(3) # weight vector; we use 3 dimensions because we have x, y, \n",
    "                        # and the threshold\n",
    "    num_iters = 0\n",
    "    missed_pts = [pair for pair in training_set if pair[1] != eval_PLA(pair[0], W)]\n",
    "    \n",
    "    while missed_pts != []:\n",
    "        missed_pt = random.choice(missed_pts)\n",
    "        missed_y = missed_pt[1]\n",
    "        missed_x = np.array(missed_pt[0]) # this is a vector\n",
    "        W += missed_y * missed_x # Update the weight vector\n",
    "        missed_pts = [pair for pair in training_set if pair[1] != eval_PLA(pair[0], W)]\n",
    "        num_iters += 1\n",
    "        \n",
    "    return num_iters, W\n",
    "\n",
    "def compute_linreg_weights(X_mat, y_vec):\n",
    "    '''Takes a matrix of training values X_mat (each row is a training instance) and\n",
    "       a target vector y_vec and computes the linear regression weight vector for the\n",
    "       data.'''\n",
    "    pseudo_inv = np.dot(inv((np.dot(X_mat.T, X_mat))), X_mat.T)\n",
    "    return np.dot(pseudo_inv, y_vec)\n",
    "\n",
    "def predict_linreg(x, weights):\n",
    "    '''Uses a pre-trained linear regression model (given by weights) to predict a binary\n",
    "       target function given data x.'''\n",
    "    print(weights)\n",
    "    print(x)\n",
    "    return np.sign(np.dot(weights, x))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lines = []\n",
    "weights_vectors = []\n",
    "in_sample_errors = []\n",
    "N = 100\n",
    "\n",
    "for _ in range(1000):\n",
    "    slope, y_int = define_f()\n",
    "    lines.append((slope, y_int))\n",
    "    training_set = build_training_set(N, slope, y_int)\n",
    "\n",
    "    # Do our linear regression\n",
    "    X = np.array([ent[0] for ent in training_set])\n",
    "    Y = np.array([ent[1] for ent in training_set], dtype=float)\n",
    "    weights = compute_linreg_weights(X, Y)\n",
    "    weights_vectors.append(weights)\n",
    "\n",
    "    # Find the in-sample error\n",
    "    predictions = np.array([predict_linreg(np.array(ent[0]), weights) for ent in training_set])\n",
    "    # Make a vector whose entries are 1 if the prediction and ground truth agree, 0 otherwise.\n",
    "    # Then the percent correct is the number of 1's in this vector divided by its length,\n",
    "    # and the percent error is 1 - percent correct\n",
    "    in_sample_error = 1 - sum(np.equal(Y, predictions).astype(int)) / N\n",
    "    in_sample_errors.append(in_sample_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.038920000000000121"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(in_sample_errors) / len(in_sample_errors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is closest to answer [c]: 0.01."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "oos_errors = []\n",
    "TEST_SET_SIZE = 1000\n",
    "# Iterate through the 1000 saved (f, weights) configs from Problem 5\n",
    "for i in range(1000):\n",
    "    slope, y_int = lines[i]\n",
    "    weights = weights_vectors[i]\n",
    "    \n",
    "    # Generate 1000 points\n",
    "    testing_set = build_training_set(TEST_SET_SIZE, slope, y_int) # not really a \"training set\"\n",
    "    \n",
    "    # Compute the error on this testing set (out of sample error)\n",
    "    ground_truths = np.array([ent[1] for ent in testing_set], dtype=float)\n",
    "    predictions = np.array([predict_linreg(np.array(ent[0]), weights) for ent in testing_set])\n",
    "    oos_error = 1 - sum(np.equal(ground_truths, predictions).astype(int)) / TEST_SET_SIZE\n",
    "    oos_errors.append(oos_error)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.047604999999999911"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(oos_errors) / len(oos_errors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is closest to answer [c]: 0.01."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sum_num_iters = 0\n",
    "for _ in range(1000):\n",
    "    slope, y_int = define_f()\n",
    "    training_set = build_training_set(10, slope, y_int)\n",
    "\n",
    "    # Do our linear regression\n",
    "    X = np.array([ent[0] for ent in training_set])\n",
    "    Y = np.array([ent[1] for ent in training_set], dtype=float)\n",
    "    weights = compute_linreg_weights(X, Y)\n",
    "\n",
    "    # Pass these weights to PLA\n",
    "    num_iters, _ = train_PLA(training_set, W=weights)\n",
    "    sum_num_iters += num_iters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.566"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum_num_iters / 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is closest to answer [a]: 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "def f(pt):\n",
    "    '''Implements the function f(x1, x2) = sign(x1^2 + x2^2 - 0.6),\n",
    "       where x1 and x2 are interpreted as the two components'''\n",
    "    return np.sign(pt[0]**2 + pt[1]**2 - 0.6)\n",
    "\n",
    "def build_dataset(N, target_func):\n",
    "    '''Build a data set of N points and use target_func to evaluate each\n",
    "       point to get the ground truth values.'''\n",
    "    dataset = []\n",
    "    for _ in range(N):\n",
    "        x = generate_point()\n",
    "        y = target_func(x)\n",
    "        dataset.append(([1.] + x, y))\n",
    "    return dataset\n",
    "\n",
    "def noisify_dataset(dataset, ratio):\n",
    "    '''Randomly flip the sign of the output in ratio of a given dataset. A new noisy dataset\n",
    "       is returned, rather than modifying the original inplace.'''\n",
    "    dataset = copy.deepcopy(dataset)\n",
    "    num_elems = len(dataset)\n",
    "    idx_subset = np.random.choice(range(num_elems), size=int(ratio * num_elems), replace=False)\n",
    "    for i in idx_subset:\n",
    "        val = dataset[i][1]\n",
    "        flipped_val = 1.0 if val == -1.0 else -1.0\n",
    "        dataset[i] = (dataset[i][0], flipped_val)\n",
    "    return dataset\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Now we can do our simulation\n",
    "in_sample_error_sum = 0\n",
    "NUM_TRIALS = 1000\n",
    "TRAINING_SIZE = 1000\n",
    "\n",
    "for _ in range(NUM_TRIALS):\n",
    "    dataset = build_dataset(TRAINING_SIZE, f)\n",
    "    dataset = noisify_dataset(dataset, .1) # Randomly flip 10% of the dataset output values\n",
    "\n",
    "    # Do our linear regression\n",
    "    X = np.array([ent[0] for ent in dataset])\n",
    "    Y = np.array([ent[1] for ent in dataset], dtype=float)\n",
    "    weights = compute_linreg_weights(X, Y)\n",
    "\n",
    "    # Find the in-sample error\n",
    "    predictions = np.array([predict_linreg(np.array(ent[0]), weights) for ent in dataset])\n",
    "    in_sample_error = 1 - sum(np.equal(Y, predictions).astype(int)) / TRAINING_SIZE\n",
    "    in_sample_error_sum += in_sample_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.50546599999999964"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_sample_error_sum / NUM_TRIALS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is closest to [d] 0.5. This makes sense because the data are highly linearly inseparable; thus, the performance is very poor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def nonlinear_transform(x):\n",
    "    '''Converts a data point of the form [1 x1 x2] to the form\n",
    "       [1, x1, x2, x1x2, x1^2 x2^2].'''\n",
    "    return [1.0, x[1], x[2], x[1] * x[2], x[1] * x[1], x[2] * x[2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def eval_a(x):\n",
    "    return np.sign(-1 - 0.05*x[1] + 0.08*x[2] + .13*x[1]*x[2] + 1.5*x[1]**2 + 1.5*x[2]**2)\n",
    "\n",
    "def eval_b(x):\n",
    "    return np.sign(-1 - 0.05*x[1] + 0.08*x[2] + .13*x[1]*x[2] + 1.5*x[1]**2 + 15*x[2]**2)\n",
    "\n",
    "def eval_c(x):\n",
    "    return np.sign(-1 - 0.05*x[1] + 0.08*x[2] + 0.13*x[1]*x[2] + 15*x[1]**2 + 1.5*x[2]**2)\n",
    "\n",
    "def eval_d(x):\n",
    "    return np.sign(-1 - 1.5*x[1] + .08*x[2] + .13*x[1]*x[2] + 0.05*x[1]**2 + .05*x[2]**2)\n",
    "\n",
    "def eval_e(x):\n",
    "    return np.sign(-1 - .05*x[1] + 0.08*x[2] + 1.5*x[1]*x[2] + 0.15*x[1]**2 + 0.15*x[2]**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataset = build_dataset(1000, f)\n",
    "dataset = noisify_dataset(dataset, .1) # Randomly flip 10% of the dataset output values\n",
    "\n",
    "# Nonlinearly transform the dataset\n",
    "X = np.array([ent[0] for ent in dataset])\n",
    "X_transform = np.array([nonlinear_transform(x) for x in X])\n",
    "Y = np.array([ent[1] for ent in dataset], dtype=float)\n",
    "# Train on the transformed data\n",
    "weights = compute_linreg_weights(X_transform, Y)\n",
    "\n",
    "# Compare the trained model vs all of the multiple choice options\n",
    "a_vs_trained = [float(predict_linreg(x, weights) == eval_a(x)) for x in X_transform]\n",
    "b_vs_trained = [float(predict_linreg(x, weights) == eval_b(x)) for x in X_transform]\n",
    "c_vs_trained = [float(predict_linreg(x, weights) == eval_c(x)) for x in X_transform]\n",
    "d_vs_trained = [float(predict_linreg(x, weights) == eval_d(x)) for x in X_transform]\n",
    "e_vs_trained = [float(predict_linreg(x, weights) == eval_e(x)) for x in X_transform]\n",
    "\n",
    "a_error = 1 - sum(a_vs_trained) / 1000\n",
    "b_error = 1 - sum(b_vs_trained) / 1000\n",
    "c_error = 1 - sum(c_vs_trained) / 1000\n",
    "d_error = 1 - sum(d_vs_trained) / 1000\n",
    "e_error = 1 - sum(e_vs_trained) / 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.015000000000000013\n",
      "0.34099999999999997\n",
      "0.365\n",
      "0.347\n",
      "0.43200000000000005\n"
     ]
    }
   ],
   "source": [
    "print(a_error)\n",
    "print(b_error)\n",
    "print(c_error)\n",
    "print(d_error)\n",
    "print(e_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The lowest error is [a], so that is our answer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "TEST_SET_SIZE = 1000\n",
    "NUM_TRIALS = 1000\n",
    "\n",
    "oos_error_sum = 0\n",
    "for _ in range(NUM_TRIALS):\n",
    "    test_set = build_dataset(TEST_SET_SIZE, f)\n",
    "    test_set = noisify_dataset(test_set, 0.1)\n",
    "    \n",
    "    # Nonlinearly transform the dataset\n",
    "    X = np.array([ent[0] for ent in test_set])\n",
    "    X_transform = np.array([nonlinear_transform(x) for x in X])\n",
    "    Y = np.array([ent[1] for ent in test_set], dtype=float)\n",
    "\n",
    "    predictions = np.array([predict_linreg(x, weights) for x in X_transform])\n",
    "    oos_error = 1 - sum(np.equal(Y, predictions).astype(int)) / TEST_SET_SIZE\n",
    "    oos_error_sum += oos_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13973900000000034"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oos_error_sum / 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is closest to [b]: 0.1, so that is our answer."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
