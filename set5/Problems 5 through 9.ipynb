{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def error_func(u, v):\n",
    "    '''This is the error function used in Problems 4 - 7'''\n",
    "    return (u * np.exp(v) - 2 * v * np.exp(-u)) ** 2\n",
    "\n",
    "def error_func_du(u, v):\n",
    "    '''Derivative of the error function wrt to u'''\n",
    "    return 2 * (u * np.exp(v) - 2 * v * np.exp(-u)) * (np.exp(v) + 2 * v * np.exp(-u))\n",
    "\n",
    "def error_func_dv(u, v):\n",
    "    '''Derivative of the error function wrt to v'''\n",
    "    return 2 * (u * np.exp(v) - 2 * v * np.exp(-u)) * (u * np.exp(v) - 2 * np.exp(-u))\n",
    "\n",
    "def error_func_grad(u, v):\n",
    "    return np.array([error_func_du(u, v), error_func_dv(u, v)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problems 5 and 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.1\n",
    "u, v = (1, 1)\n",
    "iters = 0\n",
    "\n",
    "while error_func(u, v) >= 10**-14:\n",
    "    delta_w = -1 * learning_rate * error_func_grad(u, v)\n",
    "    u += delta_w[0]\n",
    "    v += delta_w[1]\n",
    "    iters += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.1\n",
    "u, v = (1, 1)\n",
    "\n",
    "for i in range(15):\n",
    "    grad = error_func_grad(u, v)\n",
    "    u_direction = -1 * grad[0]\n",
    "    u += learning_rate * u_direction\n",
    "    # Recalculate gradient\n",
    "    grad = error_func_grad(u, v)\n",
    "    v_direction = -1 * grad[1]\n",
    "    v += learning_rate * v_direction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13981379199615315"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error_func(u, v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#### Helper functions ####\n",
    "\n",
    "def generate_point():\n",
    "    '''Generate a random point in [-1, 1] x [-1, 1]'''\n",
    "    return [random.uniform(-1, 1), random.uniform(-1, 1)]\n",
    "\n",
    "def define_f():\n",
    "    '''Return a slope and y-intercept based on two random points in\n",
    "       [-1, 1] x [-1, 1]. This defines the function f(x) = slope * x + y_int. \n",
    "       This can fail if f is vertical. However, this is extremely unlikely given \n",
    "       that our two points are chosen randomly. If it does fail, we'll get an error.'''\n",
    "    p1 = generate_point()\n",
    "    p2 = generate_point()\n",
    "    slope = (p2[1] - p1[1]) / (p2[0] - p1[0])\n",
    "    y_int = (-1 * slope * p1[0]) + p1[1] # From point-slope form\n",
    "    return slope, y_int\n",
    "\n",
    "def evaluate_point(pt, slope, y_int):\n",
    "    ''' Return 1 if the point is above f, -1 otherwise'''\n",
    "    if pt[1] >= slope * pt[0] + y_int: # pt[0] is x coord, pt[1] is y coord\n",
    "        return 1\n",
    "    return -1\n",
    "\n",
    "def build_data_set(N, slope, y_int):\n",
    "    '''Build a set of N data points of the form ([1.0, x1, x2], y). The 1.0 is the\n",
    "       artificial coordinate used to simplify the math. x1 and x2 come from\n",
    "       [-1, 1] x [-1, 1], and y is -1 or +1, depending on whether the point (x1, x2) is\n",
    "       above or below f. f is defined by f(x) = slope * x + y_int'''\n",
    "    data_set = []\n",
    "    for i in range(N):\n",
    "        xn = generate_point() \n",
    "        yn = evaluate_point(xn, slope, y_int)\n",
    "        data_set.append((np.array([1.] + xn), yn)) # Note the artificial coordinate\n",
    "    return data_set\n",
    "    \n",
    "def logit_grad(xn, yn, weights):\n",
    "    '''Evaluate the logit gradient at a single point (xn, yn).'''\n",
    "    return -1 * yn * xn / (1 + np.exp(yn * np.dot(weights.T, xn)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "N = 100\n",
    "test_set_size = 1000\n",
    "threshold = 0.01\n",
    "num_simulations = 100\n",
    "\n",
    "avg_num_epochs = 0\n",
    "avg_cross_ent_error = 0\n",
    "\n",
    "for _ in range(num_simulations):\n",
    "    # Generate the training set\n",
    "    slope, y_int = define_f()\n",
    "    training_set = build_data_set(N, slope, y_int)\n",
    "    weights = np.zeros(3)\n",
    "    old_weights = weights\n",
    "\n",
    "    # Train a logistic regression model\n",
    "    num_epochs = 0\n",
    "    while True:\n",
    "        np.random.shuffle(training_set)\n",
    "        for pt in training_set:\n",
    "            weights = weights - learning_rate  * logit_grad(pt[0], pt[1], weights)\n",
    "        num_epochs += 1\n",
    "        if np.linalg.norm(old_weights - weights) < threshold:\n",
    "            break\n",
    "        old_weights = weights\n",
    "    avg_num_epochs += num_epochs / num_simulations\n",
    "\n",
    "    # Generate the test set\n",
    "    test_set = build_data_set(test_set_size, slope, y_int)\n",
    "    cross_ent_error = 0\n",
    "\n",
    "    for pt in test_set:\n",
    "        xn = pt[0]\n",
    "        yn = pt[1]\n",
    "        cross_ent_error += (1 / test_set_size) * np.log(1 + np.exp(-1 * yn * np.dot(weights.T, xn)))\n",
    "    avg_cross_ent_error += cross_ent_error / num_simulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10322702878421613"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_cross_ent_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "334.42"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_num_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
